{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurring Neural Networks com Keras\n",
    "\n",
    "## Análise de sentimento a partir de resenhas de filmes\n",
    "\n",
    "Na verdade, é um ótimo exemplo do uso de RNN. O conjunto de dados que estamos usando consiste em resenhas de filmes geradas por usuários e classificação de se o usuário gostou ou não do filme com base em sua classificação associada.\n",
    "\n",
    "Mais informações sobre o conjunto de dados estão aqui:\n",
    "\n",
    "https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "\n",
    "Então, vamos usar um RNN para fazer análise de sentimentos em resenhas de filmes em texto!\n",
    "\n",
    "Pense em como isso é incrível. Vamos treinar uma rede neural artificial para \"ler\" resenhas de filmes e adivinhar se o autor gostou ou não do filme.\n",
    "\n",
    "Uma vez que a compreensão da linguagem escrita requer o acompanhamento de todas as palavras de uma frase, precisamos de uma rede neural recorrente para manter uma \"memória\" das palavras que vieram antes, uma vez que \"lê\" as sentenças ao longo do tempo.\n",
    "\n",
    "Em particular, usaremos células LSTM (Long Short-Term Memory) porque não queremos \"esquecer\" palavras muito rapidamente - as palavras no início de uma frase podem afetar significativamente o significado dessa frase.\n",
    "\n",
    "Vamos começar importando as coisas que precisamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora importe nossos dados de treinamento e teste. Especificamos que nos importamos apenas com as 20.000 palavras mais populares no conjunto de dados para manter as coisas um pouco fáceis de gerenciar. O conjunto de dados inclui 5.000 revisões de treinamento e 25.000 revisões de testes por algum motivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Carregando os dados...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos sentir como são esses dados. Vamos ver o primeiro recurso de treinamento, que deve representar uma crítica escrita de filme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso não parece uma resenha de filme! Mas este conjunto de dados poupou-lhe muitos problemas - eles já converteram palavras para índices baseados em números inteiros. As letras reais que compõem uma palavra realmente não importam no que diz respeito ao nosso modelo, o que importa são as próprias palavras - e nosso modelo precisa de números para trabalhar, não de letras.\n",
    "\n",
    "Portanto, lembre-se de que cada número nos recursos de treinamento representa alguma palavra específica. É uma chatice que não podemos apenas ler as resenhas em inglês como um teste para ver se a análise de sentimentos está realmente funcionando.\n",
    "\n",
    "Como são as etiquetas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eles são apenas 0 ou 1, o que indica se o revisor disse que gostou do filme ou não.\n",
    "\n",
    "Então, para recapitular, temos várias resenhas de filmes que foram convertidas em vetores de palavras representadas por inteiros e uma classificação de sentimento binário para aprendermos.\n",
    "\n",
    "O RNN pode explodir rapidamente, então, novamente, para manter as coisas fáceis de gerenciar em nosso pequeno PC, vamos limitar as revisões às primeiras 80 palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=80)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos configurar nosso modelo de rede neural! Considerando o quão complicada é uma rede neural recorrente do LSTM, é realmente incrível como isso é fácil com o Keras.\n",
    "\n",
    "Vamos começar com uma camada de embedding - isso é apenas uma etapa que converte os dados de entrada em vetores densos de tamanho fixo que é mais adequado para uma rede neural. Você geralmente vê isso em conjunto com dados de texto baseados em índice, como temos aqui. Os 20.000 indicam o tamanho do vocabulário (lembre-se que dissemos que só queríamos as 20.000 palavras mais importantes) e 128 é a dimensão de saída de 128 unidades.\n",
    "\n",
    "Em seguida, basta configurar uma camada LSTM para o próprio RNN. É tão fácil. Nós especificamos 128 para combinar com o tamanho de saída da camada Embedding e os termos de dropout para evitar overfitting, aos quais os RNNs são particularmente propensos.\n",
    "\n",
    "Finalmente, precisamos apenas resumi-lo a um único neurônio com uma função de ativação sigmoide para escolher nossa classificação de sentimento binay de 0 ou 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como este é um problema de classificação binária, usaremos a função de perda binary_crossentropy. E o otimizador Adam geralmente é uma boa escolha (sinta-se à vontade para experimentar outras pessoas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realmente treinar nosso modelo. Os da RNN, como os da CNN, são muito pesados em recursos. Manter o tamanho do lote relativamente pequeno é a chave para que isso funcione no seu PC. Na verdade, você estaria aproveitando as GPUs instaladas em vários computadores em um cluster para tornar essa escala muito melhor.\n",
    "\n",
    "## Aviso\n",
    "\n",
    "Isso levará muito tempo para ser executado, mesmo em um PC rápido! Não execute o próximo bloco, a menos que você esteja preparado para dedicar seu computador por uma hora ou mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frank\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      " - 139s - loss: 0.6580 - acc: 0.5869 - val_loss: 0.5437 - val_acc: 0.7200\n",
      "Epoch 2/15\n",
      " - 138s - loss: 0.4652 - acc: 0.7772 - val_loss: 0.4024 - val_acc: 0.8153\n",
      "Epoch 3/15\n",
      " - 136s - loss: 0.3578 - acc: 0.8446 - val_loss: 0.4024 - val_acc: 0.8172\n",
      "Epoch 4/15\n",
      " - 134s - loss: 0.2902 - acc: 0.8784 - val_loss: 0.3875 - val_acc: 0.8276\n",
      "Epoch 5/15\n",
      " - 135s - loss: 0.2342 - acc: 0.9055 - val_loss: 0.4063 - val_acc: 0.8308\n",
      "Epoch 6/15\n",
      " - 132s - loss: 0.1818 - acc: 0.9292 - val_loss: 0.4571 - val_acc: 0.8308\n",
      "Epoch 7/15\n",
      " - 124s - loss: 0.1394 - acc: 0.9476 - val_loss: 0.5458 - val_acc: 0.8177\n",
      "Epoch 8/15\n",
      " - 126s - loss: 0.1062 - acc: 0.9609 - val_loss: 0.5950 - val_acc: 0.8133\n",
      "Epoch 9/15\n",
      " - 133s - loss: 0.0814 - acc: 0.9712 - val_loss: 0.6440 - val_acc: 0.8218\n",
      "Epoch 10/15\n",
      " - 134s - loss: 0.0628 - acc: 0.9783 - val_loss: 0.6525 - val_acc: 0.8138\n",
      "Epoch 11/15\n",
      " - 136s - loss: 0.0514 - acc: 0.9822 - val_loss: 0.7252 - val_acc: 0.8143\n",
      "Epoch 12/15\n",
      " - 137s - loss: 0.0414 - acc: 0.9869 - val_loss: 0.7997 - val_acc: 0.8035\n",
      "Epoch 13/15\n",
      " - 136s - loss: 0.0322 - acc: 0.9890 - val_loss: 0.8717 - val_acc: 0.8120\n",
      "Epoch 14/15\n",
      " - 132s - loss: 0.0279 - acc: 0.9905 - val_loss: 0.9776 - val_acc: 0.8114\n",
      "Epoch 15/15\n",
      " - 140s - loss: 0.0231 - acc: 0.9918 - val_loss: 0.9317 - val_acc: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21c29ab8630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, vamos avaliar a precisão do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9316869865119457\n",
      "Test accuracy: 0.80904\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=32,\n",
    "                            verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% eh? Nada mal, considerando que nos limitamos às primeiras 80 palavras de cada revisão.\n",
    "\n",
    "Mas novamente - pare e pense sobre o que acabamos de fazer aqui! Uma rede neural que pode \"ler\" comentários e deduzir se o autor gostou do filme ou não com base nesse texto. E leva em consideração o contexto de cada palavra e sua posição na revisão - e a configuração do modelo em si foi apenas algumas linhas de código! É incrível o que você pode fazer com o Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
